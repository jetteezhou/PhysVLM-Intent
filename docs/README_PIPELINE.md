# PhysVLM-Intent Pipeline é¡¹ç›®ç»“æ„è¯´æ˜

## ğŸ“ é¡¹ç›®ç»“æ„

```
PhysVLM-Intent/
â”œâ”€â”€ pipeline/                    # Pipelineæ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py             # ä¸»Pipelineç±»
â”‚   â”œâ”€â”€ audio_processor.py      # éŸ³é¢‘å¤„ç†æ¨¡å—ï¼ˆASRï¼‰
â”‚   â”œâ”€â”€ video_processor.py      # è§†é¢‘å¤„ç†æ¨¡å—ï¼ˆåˆ†å‰²ã€å¸§é‡‡æ ·ï¼‰
â”‚   â””â”€â”€ llm_client.py          # LLMå®¢æˆ·ç«¯æ¨¡å—ï¼ˆæ„å›¾åˆ†æã€ç›®æ ‡å®šä½ï¼‰
â”œâ”€â”€ config/                      # é…ç½®æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py             # é…ç½®å’Œå¸¸é‡
â”œâ”€â”€ utils/                       # å·¥å…·å‡½æ•°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ image_utils.py          # å›¾åƒå¤„ç†å·¥å…·
â”œâ”€â”€ data_label_gen_pipeline.py  # ä¸»å…¥å£æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
â”œâ”€â”€ annotation_server.py        # æ ‡æ³¨å·¥å…·æœåŠ¡å™¨
â”œâ”€â”€ start_annotation_tool.py    # æ ‡æ³¨å·¥å…·å¯åŠ¨è„šæœ¬
â””â”€â”€ requirements.txt            # é¡¹ç›®ä¾èµ–

```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®APIå¯†é’¥

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–ç›´æ¥ä¿®æ”¹ `config/settings.py`ï¼š

```bash
export DASHSCOPE_API_KEY="your-dashscope-api-key"
export OPENAI_API_KEY="your-openai-api-key"
export OPENAI_BASE_URL="http://localhost:8000/v1"
```

### 3. ä½¿ç”¨Pipeline

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨æ–°çš„Pipelineç±»ï¼ˆæ¨èï¼‰

```python
from pipeline import IntentLabelPipeline
from config import Config

# åˆ›å»ºé…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
config = Config.from_env()

# åˆ›å»ºPipeline
pipeline = IntentLabelPipeline(config)

# æ‰§è¡Œå¤„ç†
result = pipeline.process(
    audio_path='test_data/IMG_3492.mp3',
    video_path='test_data/IMG_3492_up.mp4'
)
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨åŸæœ‰æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰

```python
from data_label_gen_pipeline import main

# ç›´æ¥è¿è¡Œmainå‡½æ•°
main()
```

æˆ–ç›´æ¥è¿è¡Œï¼š

```bash
python data_label_gen_pipeline.py
```

## ğŸ“¦ æ¨¡å—è¯´æ˜

### pipeline/pipeline.py
ä¸»Pipelineç±»ï¼Œæ•´åˆæ‰€æœ‰å¤„ç†æ­¥éª¤ï¼š
- è¯­éŸ³è¯†åˆ«
- è§†é¢‘åˆ†å‰²å’Œå¸§é‡‡æ ·
- æ„å›¾åˆ†æ
- ç›®æ ‡å®šä½

### pipeline/audio_processor.py
éŸ³é¢‘å¤„ç†ç›¸å…³åŠŸèƒ½ï¼š
- `convert_to_mono()`: éŸ³é¢‘æ ¼å¼è½¬æ¢
- `audio_to_words_with_timestamps()`: è¯­éŸ³è¯†åˆ«ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
- `print_words_with_timestamps()`: æ‰“å°è¯†åˆ«ç»“æœ

### pipeline/video_processor.py
è§†é¢‘å¤„ç†ç›¸å…³åŠŸèƒ½ï¼š
- `split_video_by_words()`: æ ¹æ®è¯æ±‡æ—¶é—´æˆ³åˆ†å‰²è§†é¢‘å¹¶é‡‡æ ·å¸§

### pipeline/llm_client.py
LLMäº¤äº’ç›¸å…³åŠŸèƒ½ï¼š
- `LLMClient`: LLMå®¢æˆ·ç«¯å°è£…ç±»
  - `analyze_video_intent()`: åˆ†æè§†é¢‘æ„å›¾
  - `extract_object_descriptions()`: æå–ç‰©å“æè¿°
  - `locate_object_in_image()`: åœ¨å›¾åƒä¸­å®šä½ç‰©å“

### config/settings.py
é…ç½®å’Œå¸¸é‡ï¼š
- APIå¯†é’¥é…ç½®
- æ¨¡å‹é…ç½®
- éŸ³é¢‘/è§†é¢‘å¤„ç†å‚æ•°

### utils/image_utils.py
å›¾åƒå¤„ç†å·¥å…·ï¼š
- `image_to_base64()`: å›¾åƒè½¬base64ç¼–ç 

## ğŸ”§ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹åœ¨ `config/settings.py` ä¸­ï¼š

```python
# APIé…ç½®
DASHSCOPE_API_KEY = "your-api-key"
OPENAI_API_KEY = "your-api-key"
OPENAI_BASE_URL = "http://localhost:8000/v1"

# æ¨¡å‹é…ç½®
ASR_MODEL = "fun-asr-realtime"
LLM_MODEL = "gemini-2.5-flash"

# è§†é¢‘å¤„ç†é…ç½®
DEFAULT_SAMPLING_INTERVAL = 300  # æ¯«ç§’
DEFAULT_OUTPUT_DIR = "output_frames"
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### è‡ªå®šä¹‰é…ç½®

```python
from pipeline import IntentLabelPipeline
from config import Config

# è‡ªå®šä¹‰é…ç½®
config = Config(
    sampling_interval=200,  # 200msé‡‡æ ·é—´éš”
    output_dir="custom_output",  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
    llm_model="custom-model"  # è‡ªå®šä¹‰æ¨¡å‹
)

pipeline = IntentLabelPipeline(config)
result = pipeline.process(audio_path, video_path)
```

### å•ç‹¬ä½¿ç”¨å„ä¸ªæ¨¡å—

```python
from pipeline.audio_processor import audio_to_words_with_timestamps
from pipeline.video_processor import split_video_by_words
from pipeline.llm_client import LLMClient

# è¯­éŸ³è¯†åˆ«
success, words_list = audio_to_words_with_timestamps("audio.mp3")

# è§†é¢‘å¤„ç†ï¼ˆè¿”å›result_dataå’Œæœ€åä¸€å¸§è·¯å¾„ï¼‰
result_data, last_frame_path = split_video_by_words("video.mp4", words_list)

# LLMåˆ†æ
llm_client = LLMClient(api_key="...", base_url="...")
description = llm_client.analyze_video_intent(result_data)
```

## ğŸ”„ è¿ç§»æŒ‡å—

å¦‚æœä½ ä¹‹å‰ä½¿ç”¨çš„æ˜¯ `data_label_gen_pipeline.py` ä¸­çš„å‡½æ•°ï¼Œç°åœ¨å¯ä»¥ï¼š

1. **ç»§ç»­ä½¿ç”¨åŸæœ‰æ¥å£**ï¼š`data_label_gen_pipeline.py` å·²æ›´æ–°ä¸ºå‘åå…¼å®¹çš„å…¥å£æ–‡ä»¶
2. **è¿ç§»åˆ°æ–°æ¥å£**ï¼šä½¿ç”¨ `IntentLabelPipeline` ç±»ï¼Œä»£ç æ›´ç®€æ´

## ğŸ“„ è¾“å‡ºæ ¼å¼

Pipelineä¼šç”Ÿæˆ `pipeline_data.json` æ–‡ä»¶ï¼ŒåŒ…å«ï¼š

```json
{
  "video_path": "è§†é¢‘è·¯å¾„",
  "last_image_path": "æœ€åä¸€å¼ å›¾åƒè·¯å¾„",
  "video_description": "è§†é¢‘æè¿°",
  "result_data": [...],
  "objects": [
    {
      "id": 0,
      "description": "ç‰©å“æè¿°",
      "point": [500, 300],
      "label": "ç‰©å“æ ‡ç­¾",
      "pixel_coords": [576, 540],
      "normalized_coords": [0.3, 0.5]
    }
  ],
  "image_dimensions": {
    "width": 1920,
    "height": 1080
  }
}
```

