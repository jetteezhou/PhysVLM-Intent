#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from flask import Flask, request, jsonify, send_from_directory, send_file
from flask_cors import CORS
import json
import os
import sys
import logging
from datetime import datetime
import shutil

# è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
DATA_FILE = os.path.join(PROJECT_ROOT, 'pipeline/outputs/pipeline_data.json')
BACKUP_DIR = os.path.join(PROJECT_ROOT, 'annotation_backups')
HTML_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'annotation_tool.html')

# ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
if not os.path.exists(BACKUP_DIR):
    os.makedirs(BACKUP_DIR)

@app.route('/')
def index():
    """è¿”å›æ ‡æ³¨å·¥å…·é¡µé¢"""
    return send_file(HTML_FILE)

@app.route('/pipeline_data.json')
def get_pipeline_data():
    """è·å–ç®¡é“æ•°æ®"""
    try:
        if not os.path.exists(DATA_FILE):
            return jsonify({'error': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info("æˆåŠŸåŠ è½½ç®¡é“æ•°æ®")
        return jsonify(data)
    except Exception as e:
        logger.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/save_annotations', methods=['POST'])
def save_annotations():
    """ä¿å­˜æ ‡æ³¨ç»“æœ"""
    try:
        request_data = request.get_json()
        
        if not request_data:
            return jsonify({'error': 'æ²¡æœ‰æ¥æ”¶åˆ°æ•°æ®'}), 400
        
        # å…¼å®¹æ–°æ—§ä¸¤ç§æ ¼å¼ï¼šæ–°æ ¼å¼åŒ…å« data å’Œ target_fileï¼Œæ—§æ ¼å¼ç›´æ¥æ˜¯æ•°æ®
        if isinstance(request_data, dict) and 'data' in request_data:
            # æ–°æ ¼å¼ï¼šåŒ…å«ç›®æ ‡æ–‡ä»¶è·¯å¾„
            data = request_data['data']
            target_file = request_data.get('target_file')
        else:
            # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯æ•°æ®ï¼Œä¿å­˜åˆ°é»˜è®¤æ–‡ä»¶
            data = request_data
            target_file = None
        
        # ç¡®å®šä¿å­˜çš„ç›®æ ‡æ–‡ä»¶è·¯å¾„
        if target_file:
            # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶è·¯å¾„ï¼Œä¿å­˜åˆ°è¯¥æ–‡ä»¶
            # å¤„ç†ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
            if os.path.isabs(target_file):
                save_file = target_file
            else:
                # ç›¸å¯¹è·¯å¾„ï¼Œä»é¡¹ç›®æ ¹ç›®å½•å¼€å§‹
                save_file = os.path.join(PROJECT_ROOT, target_file)
        else:
            # æ²¡æœ‰æŒ‡å®šæ–‡ä»¶ï¼Œä¿å­˜åˆ°é»˜è®¤æ–‡ä»¶
            save_file = DATA_FILE
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        save_dir = os.path.dirname(save_file)
        if save_dir and not os.path.exists(save_dir):
            os.makedirs(save_dir, exist_ok=True)
        
        # åˆ›å»ºå¤‡ä»½
        if os.path.exists(save_file):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = os.path.join(BACKUP_DIR, f'pipeline_data_backup_{timestamp}.json')
            shutil.copy2(save_file, backup_file)
            logger.info(f"åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_file}")
        
        # ä¿å­˜åˆ°ç›®æ ‡æ–‡ä»¶
        with open(save_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ ‡æ³¨æ•°æ®ä¿å­˜æˆåŠŸ: {save_file}")
        
        # åŒæ—¶ä¿å­˜ä¸€ä»½å¸¦æ—¶é—´æˆ³çš„å‰¯æœ¬
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        annotated_file = os.path.join(BACKUP_DIR, f'annotated_data_{timestamp}.json')
        with open(annotated_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True, 
            'message': 'æ ‡æ³¨ç»“æœä¿å­˜æˆåŠŸ',
            'saved_file': save_file,
            'backup_file': annotated_file
        })
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ ‡æ³¨æ•°æ®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/get_annotations_history')
def get_annotations_history():
    """è·å–æ ‡æ³¨å†å²è®°å½•"""
    try:
        history = []
        if os.path.exists(BACKUP_DIR):
            for filename in os.listdir(BACKUP_DIR):
                if filename.startswith('annotated_data_') and filename.endswith('.json'):
                    filepath = os.path.join(BACKUP_DIR, filename)
                    stat = os.stat(filepath)
                    history.append({
                        'filename': filename,
                        'filepath': filepath,
                        'size': stat.st_size,
                        'modified_time': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                    })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        history.sort(key=lambda x: x['modified_time'], reverse=True)
        
        return jsonify({'history': history})
        
    except Exception as e:
        logger.error(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/load_annotation/<filename>')
def load_annotation(filename):
    """åŠ è½½æŒ‡å®šçš„æ ‡æ³¨æ–‡ä»¶"""
    try:
        filepath = os.path.join(BACKUP_DIR, filename)
        
        if not os.path.exists(filepath):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"æˆåŠŸåŠ è½½æ ‡æ³¨æ–‡ä»¶: {filename}")
        return jsonify(data)
        
    except Exception as e:
        logger.error(f"åŠ è½½æ ‡æ³¨æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/export_annotations')
def export_annotations():
    """å¯¼å‡ºå½“å‰æ ‡æ³¨æ•°æ®"""
    try:
        if not os.path.exists(DATA_FILE):
            return jsonify({'error': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_filename = f'exported_annotations_{timestamp}.json'
        
        return send_file(
            DATA_FILE,
            as_attachment=True,
            download_name=export_filename,
            mimetype='application/json'
        )
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ ‡æ³¨æ•°æ®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/reset_annotations', methods=['POST'])
def reset_annotations():
    """é‡ç½®æ ‡æ³¨æ•°æ®åˆ°åŸå§‹çŠ¶æ€"""
    try:
        # æŸ¥æ‰¾æœ€æ—©çš„å¤‡ä»½æ–‡ä»¶
        backup_files = []
        if os.path.exists(BACKUP_DIR):
            for filename in os.listdir(BACKUP_DIR):
                if filename.startswith('pipeline_data_backup_') and filename.endswith('.json'):
                    filepath = os.path.join(BACKUP_DIR, filename)
                    stat = os.stat(filepath)
                    backup_files.append((filepath, stat.st_mtime))
        
        if not backup_files:
            return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶'}), 404
        
        # é€‰æ‹©æœ€æ—©çš„å¤‡ä»½æ–‡ä»¶
        backup_files.sort(key=lambda x: x[1])
        original_backup = backup_files[0][0]
        
        # æ¢å¤åŸå§‹æ•°æ®
        shutil.copy2(original_backup, DATA_FILE)
        
        logger.info(f"ä»å¤‡ä»½æ–‡ä»¶æ¢å¤æ•°æ®: {original_backup}")
        return jsonify({
            'success': True,
            'message': 'å·²é‡ç½®åˆ°åŸå§‹çŠ¶æ€',
            'restored_from': original_backup
        })
        
    except Exception as e:
        logger.error(f"é‡ç½®æ ‡æ³¨æ•°æ®å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/images/<path:filename>')
def serve_image(filename):
    """æä¾›å›¾åƒæ–‡ä»¶æœåŠ¡"""
    try:
        # è§£ç URLç¼–ç çš„æ–‡ä»¶å
        import urllib.parse
        filename = urllib.parse.unquote(filename)
        
        # æ”¯æŒå¤šç§å¯èƒ½çš„å›¾åƒè·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
        possible_paths = [
            PROJECT_ROOT,  # é¡¹ç›®æ ¹ç›®å½•
            os.path.join(PROJECT_ROOT, 'pipeline/outputs'),  # è¾“å‡ºç›®å½•
            os.path.join(PROJECT_ROOT, 'pipeline/outputs/output_frames'),  # å¸§è¾“å‡ºç›®å½•
            # æ³¨æ„ï¼štest_data ç›®å½•å·²ç§»é™¤ï¼Œå®é™…æ•°æ®åº”ä½¿ç”¨æ•°æ®é‡‡é›†å·¥å…·ç®¡ç†
        ]
        
        # é¦–å…ˆå°è¯•ä½œä¸ºç›¸å¯¹è·¯å¾„æŸ¥æ‰¾
        for path in possible_paths:
            full_path = os.path.join(path, filename)
            if os.path.exists(full_path) and os.path.isfile(full_path):
                return send_file(full_path)
        
        # å¦‚æœæ–‡ä»¶åæ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥å°è¯•è®¿é—®
        if os.path.isabs(filename) and os.path.exists(filename):
            return send_file(filename)
        
        # å¦‚æœæ–‡ä»¶åæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•ä»é¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾
        relative_path = os.path.join(PROJECT_ROOT, filename)
        if os.path.exists(relative_path) and os.path.isfile(relative_path):
            return send_file(relative_path)
        
        logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        return jsonify({'error': f'å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {filename}'}), 404
        
    except Exception as e:
        logger.error(f"æä¾›å›¾åƒæ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/validate_data')
def validate_data():
    """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
    try:
        if not os.path.exists(DATA_FILE):
            return jsonify({'valid': False, 'error': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'})
        
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['video_path', 'last_image_path', 'objects', 'image_dimensions']
        missing_fields = [field for field in required_fields if field not in data]
        
        if missing_fields:
            return jsonify({
                'valid': False, 
                'error': f'ç¼ºå°‘å¿…è¦å­—æ®µ: {", ".join(missing_fields)}'
            })
        
        # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„ï¼‰
        image_path = data.get('last_image_path_absolute') or data.get('last_image_path', '')
        if image_path:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not os.path.isabs(image_path):
                image_path = os.path.join(PROJECT_ROOT, image_path)
            image_exists = os.path.exists(image_path)
        else:
            image_exists = False
        
        # æ£€æŸ¥ç‰©å“æ•°æ®
        objects_valid = True
        object_errors = []
        
        for i, obj in enumerate(data['objects']):
            if 'pixel_coords' not in obj or 'description' not in obj:
                objects_valid = False
                object_errors.append(f'ç‰©å“ {i+1} ç¼ºå°‘å¿…è¦å­—æ®µ')
        
        return jsonify({
            'valid': missing_fields == [] and objects_valid,
            'image_exists': image_exists,
            'objects_count': len(data['objects']),
            'errors': object_errors,
            'image_path': data.get('last_image_path_absolute') or data.get('last_image_path', '')
        })
        
    except Exception as e:
        logger.error(f"éªŒè¯æ•°æ®å¤±è´¥: {e}")
        return jsonify({'valid': False, 'error': str(e)})

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'é¡µé¢ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨æ ‡æ³¨å·¥å…·æœåŠ¡å™¨...")
    print("ğŸ“‹ è®¿é—®åœ°å€: http://localhost:5001")
    print("ğŸ’¾ æ•°æ®æ–‡ä»¶: pipeline_data.json")
    print("ğŸ“ å¤‡ä»½ç›®å½•: annotation_backups/")
    print("=" * 50)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(DATA_FILE):
        print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {DATA_FILE}")
    else:
        print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {DATA_FILE}")
        print("   è¯·å…ˆè¿è¡Œ asr_test.py ç”Ÿæˆæ•°æ®æ–‡ä»¶")
    
    app.run(host='0.0.0.0', port=5001, debug=True)
