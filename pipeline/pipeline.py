"""ä¸»Pipelineæ¨¡å—"""
import os
import sys
import json
import cv2
import tempfile
import shutil
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from pipeline.audio_processor import audio_to_words_with_timestamps, print_words_with_timestamps
from pipeline.video_processor import split_video_by_words
from pipeline.video_preprocessor import extract_audio_and_video
from pipeline.llm_client import LLMClient
from config.settings import Config, PIPELINE_DATA_FILE


class IntentLabelPipeline:
    """æ„å›¾æ¨ç†ä¸ç›®æ ‡å®šä½æ•°æ®æ ‡æ³¨Pipeline"""
    
    def __init__(self, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–Pipeline
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or Config.from_env()
        self.llm_client = LLMClient(
            api_key=self.config.openai_api_key,
            base_url=self.config.openai_base_url,
            model_video_analysis=self.config.llm_model_video_analysis,
            model_object_description=self.config.llm_model_object_description,
            model_object_location=self.config.llm_model_object_location,
            # ä¸åŒç¯èŠ‚çš„APIé…ç½®
            api_key_video_analysis=self.config.openai_api_key_video_analysis,
            base_url_video_analysis=self.config.openai_base_url_video_analysis,
            api_key_object_description=self.config.openai_api_key_object_description,
            base_url_object_description=self.config.openai_base_url_object_description,
            api_key_object_location=self.config.openai_api_key_object_location,
            base_url_object_location=self.config.openai_base_url_object_location,
        )
    
    def process(
        self,
        input_video_path: str,
        output_file: Optional[str] = None,
        keep_extracted_files: bool = False
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        Args:
            input_video_path: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒmp4ã€movç­‰æ ¼å¼ï¼‰
            output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            keep_extracted_files: æ˜¯å¦ä¿ç•™æå–çš„éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶ï¼Œé»˜è®¤Falseï¼ˆä¸´æ—¶æ–‡ä»¶ä¼šè¢«åˆ é™¤ï¼‰
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        output_file = output_file or PIPELINE_DATA_FILE
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if not output_dir:  # å¦‚æœoutput_fileåªæœ‰æ–‡ä»¶åï¼Œæ²¡æœ‰ç›®å½•éƒ¨åˆ†
            output_dir = self.config.output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # 0. è§†é¢‘é¢„å¤„ç†ï¼šä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘å’Œè§†é¢‘
        print("\n@@@ å¼€å§‹è§†é¢‘é¢„å¤„ç†...")
        if not os.path.exists(input_video_path):
            raise ValueError(f"è¾“å…¥è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_video_path}")
        
        # æå–éŸ³é¢‘å’Œè§†é¢‘åˆ°ä¸´æ—¶ç›®å½•æˆ–è¾“å‡ºç›®å½•
        temp_dir = None
        if not keep_extracted_files:
            temp_dir = tempfile.mkdtemp()
            extract_dir = temp_dir
        else:
            extract_dir = output_dir
        
        audio_path, video_path = extract_audio_and_video(
            input_video_path,
            output_dir=extract_dir
        )
        
        if audio_path is None or video_path is None:
            raise ValueError("è§†é¢‘é¢„å¤„ç†å¤±è´¥ï¼šæ— æ³•æå–éŸ³é¢‘æˆ–è§†é¢‘")
        
        try:
            # 1. è¯­éŸ³è¯†åˆ«
            print("\n@@@ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
            success, words_list = audio_to_words_with_timestamps(
                audio_path,
                api_key=self.config.dashscope_api_key
            )
            
            if not success or not words_list:
                raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥")
            
            print_words_with_timestamps(words_list)
            
            # 2. è§†é¢‘åˆ†å‰²å’Œå¸§é‡‡æ ·
            print("\n@@@ å¼€å§‹å¤„ç†è§†é¢‘åˆ†å‰²...")
            if not os.path.exists(video_path):
                raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            
            # æå–è§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºå­æ–‡ä»¶å¤¹å
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            frames_output_dir = os.path.join(self.config.output_dir, "output_frames", video_name)
            
            result_data, last_image_path = split_video_by_words(
                video_path,
                words_list,
                output_dir=frames_output_dir,
                sampling_interval=self.config.sampling_interval
            )
            
            if not result_data:
                raise ValueError("è§†é¢‘å¤„ç†å¤±è´¥")
            
            if not last_image_path:
                raise ValueError("è§†é¢‘å¤„ç†å¤±è´¥ï¼šæœªèƒ½ä¿å­˜æœ€åä¸€å¸§")
            
            print("\n@@@ è§†é¢‘å¤„ç†å®Œæˆï¼")
            print(f"@@@ æœ€åä¸€å¸§è·¯å¾„: {last_image_path}")
            
            # 3. åˆ†æè§†é¢‘æ„å›¾å’Œç‰©å“æè¿°
            print("\n@@@ å¼€å§‹åˆ†æè§†é¢‘æ„å›¾å’Œç‰©å“æè¿°...")
            video_description = self.llm_client.analyze_video_intent(result_data)
            print("\n@@@ è§†é¢‘æè¿°: ", video_description)
            
            # 4. æå–ç‰©å“æè¿°
            print("\n@@@ å¼€å§‹æå–ç‰©å“æè¿°...")
            object_descriptions = self.llm_client.extract_object_descriptions(video_description)
            print("\n@@@ æå–çš„ç‰©å“æè¿°: ", object_descriptions)
            
            # 5. å®šä½ç‰©å“å¹¶ç”Ÿæˆç»“æœ
            print("\n@@@ å¼€å§‹å®šä½ç‰©å“...")
            image = cv2.imread(last_image_path)
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {last_image_path}")
            
            image_height, image_width = image.shape[:2]
            objects = []
            
            for i, description in enumerate(object_descriptions):
                print(f"\n@@@ å¤„ç†ç‰©å“ {i+1}: {description}")
                point_data = self.llm_client.locate_object_in_image(description, last_image_path)
                
                point = point_data['point']
                label = point_data['label']
                
                # å½’ä¸€åŒ–çš„ [y, x] åæ ‡ï¼Œ0-1000
                point_x = int(point[1]) / 1000
                point_y = int(point[0]) / 1000
                
                # è½¬åŒ–ä¸ºå›¾åƒä¸­çš„ç»å¯¹åƒç´ åæ ‡
                point_u = int(point_x * image_width)
                point_v = int(point_y * image_height)
                
                print(f"@@@ ç‰©å“point at image: ({point_u}, {point_v})")
                
                # åœ¨å›¾åƒä¸­ç”»å‡ºç‰©å“çš„ä¸­å¿ƒç‚¹
                cv2.circle(image, (point_u, point_v), 8, (0, 0, 255), -1)
                
                objects.append({
                    "id": i,
                    "description": description,
                    "point": point,  # å½’ä¸€åŒ–åæ ‡ [y, x] 0-1000
                    "label": label,
                    "pixel_coords": [point_u, point_v],  # ç»å¯¹åƒç´ åæ ‡ [x, y]
                    "normalized_coords": [point_x, point_y]  # å½’ä¸€åŒ–åæ ‡ [x, y] 0-1
                })
            
            # ä¿å­˜æ ‡æ³¨ç»“æœå›¾åƒ
            result_image_path = os.path.join(output_dir, "pipeline_point_result.jpg")
            cv2.imwrite(result_image_path, image)
            print(f"\n@@@ ç‰©å“å®šä½ç»“æœå·²ä¿å­˜åˆ°: {result_image_path}")
            
            # 6. æ„å»ºå¹¶ä¿å­˜ç»“æœæ•°æ®
            # å°†è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼Œä»¥ä¾¿æ ‡æ³¨å·¥å…·èƒ½å¤Ÿæ­£ç¡®è®¿é—®
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            
            def get_relative_path(path):
                """è·å–ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„"""
                if not path:
                    return path
                try:
                    abs_path = os.path.abspath(path)
                    if abs_path.startswith(project_root):
                        return os.path.relpath(abs_path, project_root)
                    return path
                except:
                    return path
            
            pipeline_data = {
                "input_video_path": get_relative_path(input_video_path),
                "video_path": get_relative_path(video_path),
                "audio_path": get_relative_path(audio_path),
                "last_image_path": get_relative_path(last_image_path),
                "last_image_path_absolute": last_image_path,  # ä¿ç•™ç»å¯¹è·¯å¾„ä½œä¸ºå¤‡ç”¨
                "video_description": video_description,
                "result_data": result_data,
                "objects": objects,
                "image_dimensions": {
                    "width": image_width,
                    "height": image_height
                }
            }
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(pipeline_data, f, ensure_ascii=False, indent=2)
            
            print(f"\n@@@ ç®¡é“æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            
            return pipeline_data
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_dir and os.path.exists(temp_dir):
                try:
                    shutil.rmtree(temp_dir)
                    print(f"\n@@@ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶ç›®å½•: {temp_dir}")
                except Exception as e:
                    print(f"\n@@@ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºé…ç½®
    config = Config.from_env()
    
    # åˆ›å»ºPipeline
    pipeline = IntentLabelPipeline(config)
    
    # æ‰§è¡Œå¤„ç† - ç°åœ¨åªéœ€è¦ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è·¯å¾„
    # æ³¨æ„ï¼šå»ºè®®ä½¿ç”¨ workflow_manager.py æ¥è¿è¡Œå®Œæ•´çš„æµç¨‹
    # è¿™é‡Œæä¾›ä¸€ä¸ªç¤ºä¾‹è·¯å¾„ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºä½ çš„è§†é¢‘è·¯å¾„
    input_video_path = input("è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæˆ–æŒ‰å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰: ").strip()
    
    if not input_video_path:
        # å°è¯•ä»é‡‡é›†å·¥å…·çš„æ•°æ®ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘
        collection_data_dir = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            'tools/data_collection/datas'
        )
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªè§†é¢‘æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        input_video_path = None
        for root, dirs, files in os.walk(collection_data_dir):
            for file in files:
                if file.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):
                    input_video_path = os.path.join(root, file)
                    print(f"ä½¿ç”¨æ‰¾åˆ°çš„è§†é¢‘æ–‡ä»¶: {input_video_path}")
                    break
            if input_video_path:
                break
        
        if not input_video_path:
            print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šè·¯å¾„")
            print("ğŸ’¡ æç¤º: ä½¿ç”¨ python workflow_manager.py å¯ä»¥æ›´æ–¹ä¾¿åœ°é€‰æ‹©è§†é¢‘")
            return
    
    try:
        result = pipeline.process(input_video_path)
        print("\nâœ… Pipelineæ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š å¤„ç†äº† {len(result['objects'])} ä¸ªç‰©å“")
    except Exception as e:
        print(f"\nâŒ Pipelineæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()

