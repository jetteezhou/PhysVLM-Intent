"""ä¸»Pipelineæ¨¡å—"""
import os
import sys
import json
import cv2
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from pipeline.audio_processor import audio_to_words_with_timestamps, print_words_with_timestamps
from pipeline.video_processor import split_video_by_words
from pipeline.llm_client import LLMClient
from config.settings import Config, PIPELINE_DATA_FILE


class IntentLabelPipeline:
    """æ„å›¾æ¨ç†ä¸ç›®æ ‡å®šä½æ•°æ®æ ‡æ³¨Pipeline"""
    
    def __init__(self, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–Pipeline
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or Config.from_env()
        self.llm_client = LLMClient(
            api_key=self.config.openai_api_key,
            base_url=self.config.openai_base_url,
            model_video_analysis=self.config.llm_model_video_analysis,
            model_object_description=self.config.llm_model_object_description,
            model_object_location=self.config.llm_model_object_location,
            # ä¸åŒç¯èŠ‚çš„APIé…ç½®
            api_key_video_analysis=self.config.openai_api_key_video_analysis,
            base_url_video_analysis=self.config.openai_base_url_video_analysis,
            api_key_object_description=self.config.openai_api_key_object_description,
            base_url_object_description=self.config.openai_base_url_object_description,
            api_key_object_location=self.config.openai_api_key_object_location,
            base_url_object_location=self.config.openai_base_url_object_location,
        )
    
    def process(
        self,
        audio_path: str,
        video_path: str,
        output_file: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        output_file = output_file or PIPELINE_DATA_FILE
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_file)
        if not output_dir:  # å¦‚æœoutput_fileåªæœ‰æ–‡ä»¶åï¼Œæ²¡æœ‰ç›®å½•éƒ¨åˆ†
            output_dir = self.config.output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # 1. è¯­éŸ³è¯†åˆ«
        print("\n@@@ å¼€å§‹è¯­éŸ³è¯†åˆ«...")
        success, words_list = audio_to_words_with_timestamps(
            audio_path,
            api_key=self.config.dashscope_api_key
        )
        
        if not success or not words_list:
            raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥")
        
        print_words_with_timestamps(words_list)
        
        # 2. è§†é¢‘åˆ†å‰²å’Œå¸§é‡‡æ ·
        print("\n@@@ å¼€å§‹å¤„ç†è§†é¢‘åˆ†å‰²...")
        if not os.path.exists(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        # æå–è§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºå­æ–‡ä»¶å¤¹å
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        frames_output_dir = os.path.join(self.config.output_dir, "output_frames", video_name)
        
        result_data = split_video_by_words(
            video_path,
            words_list,
            output_dir=frames_output_dir,
            sampling_interval=self.config.sampling_interval
        )
        
        if not result_data:
            raise ValueError("è§†é¢‘å¤„ç†å¤±è´¥")
        
        last_image_path = result_data[-1]['å›¾ç‰‡è·¯å¾„åˆ—è¡¨'][-1]
        print("\n@@@ è§†é¢‘å¤„ç†å®Œæˆï¼")
        
        # 3. åˆ†æè§†é¢‘æ„å›¾å’Œç‰©å“æè¿°
        print("\n@@@ å¼€å§‹åˆ†æè§†é¢‘æ„å›¾å’Œç‰©å“æè¿°...")
        video_description = self.llm_client.analyze_video_intent(result_data)
        print("\n@@@ è§†é¢‘æè¿°: ", video_description)
        
        # 4. æå–ç‰©å“æè¿°
        print("\n@@@ å¼€å§‹æå–ç‰©å“æè¿°...")
        object_descriptions = self.llm_client.extract_object_descriptions(video_description)
        print("\n@@@ æå–çš„ç‰©å“æè¿°: ", object_descriptions)
        
        # 5. å®šä½ç‰©å“å¹¶ç”Ÿæˆç»“æœ
        print("\n@@@ å¼€å§‹å®šä½ç‰©å“...")
        image = cv2.imread(last_image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {last_image_path}")
        
        image_height, image_width = image.shape[:2]
        objects = []
        
        for i, description in enumerate(object_descriptions):
            print(f"\n@@@ å¤„ç†ç‰©å“ {i+1}: {description}")
            point_data = self.llm_client.locate_object_in_image(description, last_image_path)
            
            point = point_data['point']
            label = point_data['label']
            
            # å½’ä¸€åŒ–çš„ [y, x] åæ ‡ï¼Œ0-1000
            point_x = int(point[1]) / 1000
            point_y = int(point[0]) / 1000
            
            # è½¬åŒ–ä¸ºå›¾åƒä¸­çš„ç»å¯¹åƒç´ åæ ‡
            point_u = int(point_x * image_width)
            point_v = int(point_y * image_height)
            
            print(f"@@@ ç‰©å“point at image: ({point_u}, {point_v})")
            
            # åœ¨å›¾åƒä¸­ç”»å‡ºç‰©å“çš„ä¸­å¿ƒç‚¹
            cv2.circle(image, (point_u, point_v), 8, (0, 0, 255), -1)
            
            objects.append({
                "id": i,
                "description": description,
                "point": point,  # å½’ä¸€åŒ–åæ ‡ [y, x] 0-1000
                "label": label,
                "pixel_coords": [point_u, point_v],  # ç»å¯¹åƒç´ åæ ‡ [x, y]
                "normalized_coords": [point_x, point_y]  # å½’ä¸€åŒ–åæ ‡ [x, y] 0-1
            })
        
        # ä¿å­˜æ ‡æ³¨ç»“æœå›¾åƒ
        result_image_path = os.path.join(output_dir, "pipeline_point_result.jpg")
        cv2.imwrite(result_image_path, image)
        print(f"\n@@@ ç‰©å“å®šä½ç»“æœå·²ä¿å­˜åˆ°: {result_image_path}")
        
        # 6. æ„å»ºå¹¶ä¿å­˜ç»“æœæ•°æ®
        pipeline_data = {
            "video_path": video_path,
            "last_image_path": last_image_path,
            "video_description": video_description,
            "result_data": result_data,
            "objects": objects,
            "image_dimensions": {
                "width": image_width,
                "height": image_height
            }
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(pipeline_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n@@@ ç®¡é“æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        
        return pipeline_data


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºé…ç½®
    config = Config.from_env()
    
    # åˆ›å»ºPipeline
    pipeline = IntentLabelPipeline(config)
    
    # æ‰§è¡Œå¤„ç†
    audio_path = 'test_data/IMG_3492.mp3'
    video_path = 'test_data/IMG_3492_up.mp4'
    
    try:
        result = pipeline.process(audio_path, video_path)
        print("\nâœ… Pipelineæ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š å¤„ç†äº† {len(result['objects'])} ä¸ªç‰©å“")
    except Exception as e:
        print(f"\nâŒ Pipelineæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()

